{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"device {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class Optimiser(ABC):\n",
    "    def __init__(self, weight, lr=0.1):\n",
    "        self.weight = weight\n",
    "        self.lr = lr\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def step(self, weight, grad):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, weight, grad):\n",
    "        return self.step(weight, grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vanillaSGD(Optimiser):\n",
    "    def __init__(self, weight, lr=0.1):\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self, weight, grad):\n",
    "        weight -= self.lr * grad\n",
    "        return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignSGD(Optimiser):\n",
    "    def __init__(self, weight, lr=0.1):\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self, weight, grad):\n",
    "        weight -= self.lr * torch.sign(grad)\n",
    "        return weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MomentumSGD(Optimiser):\n",
    "    def __init__(self,weight,lr=0.1,momentum_coeff=0.9):\n",
    "        self.momentum_coeff = momentum_coeff\n",
    "        self.lr = lr\n",
    "        self.weight_momentum = torch.zeros_like(weight)\n",
    "\n",
    "    def step(self, weight, grad):\n",
    "        self.weight_momentum = self.momentum_coeff * self.weight_momentum + grad\n",
    "        weight -= self.lr * self.weight_momentum\n",
    "        return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NAG(Optimiser): # Nesterov\n",
    "    def __init__(self, weight, lr=0.1, momentum_coeff=0.9):\n",
    "        self.momentum_coeff = momentum_coeff\n",
    "        self.weight_momentum = torch.zeros_like(weight)\n",
    "        self.lr = lr\n",
    "    \n",
    "    def step(self, weight, grad):\n",
    "        self.weight_momentum = self.momentum_coeff * self.weight_momentum + grad\n",
    "        weight -= self.lr * (grad + self.momentum_coeff * self.weight_momentum)\n",
    "        return weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QHM(Optimiser): # Quasi-Hyperbolic Momentum\n",
    "    def __init__(self, weight, lr=0.1, momentum_coeff=0.9, nu=0.7):\n",
    "        self.lr = lr\n",
    "        self.momentum_coeff = momentum_coeff\n",
    "        self.nu = nu\n",
    "        self.weight_momentum = torch.zeros_like(weight, requires_grad=True)\n",
    "    \n",
    "    def step(self, weight, grad):\n",
    "        self.weight_momentum = self.momentum_coeff * self.weight_momentum + (1 - self.momentum_coeff) * grad\n",
    "        update = (1 - self.nu) * grad + self.nu * self.weight_momentum\n",
    "        weight -= self.lr * update\n",
    "        return weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-10\n",
    "\n",
    "class RMSprop(Optimiser):\n",
    "    def __init__(self, weight, lr=0.01, momentum_coeff=0.9):\n",
    "        self.momentum_coeff = momentum_coeff\n",
    "        self.weight_momentum = torch.zeros_like(weight)\n",
    "        self.lr = lr\n",
    "        \n",
    "    def step(self, weight, grad):\n",
    "        self.weight_momentum = self.momentum_coeff * self.weight_momentum + (1 - self.momentum_coeff) * grad**2\n",
    "        weight -= self.lr * grad / (torch.sqrt(self.weight_momentum) + EPSILON)\n",
    "        return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad(Optimiser):\n",
    "    def __init__(self, weight, lr=0.1):\n",
    "        self.weight_momentum = torch.zeros_like(weight)\n",
    "        self.lr = lr\n",
    "    \n",
    "    def step(self, weight, grad):\n",
    "        self.weight_momentum = self.weight_momentum + grad**2\n",
    "        weight -= self.lr * grad / (torch.sqrt(self.weight_momentum) + EPSILON)\n",
    "        return weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DELTA_EPSILON = 1e-6\n",
    "\n",
    "class AdaDelta(Optimiser):\n",
    "    def __init__(self, weight, lr=1.0, momentum_coeff=0.75):\n",
    "        self.momentum_coeff = momentum_coeff\n",
    "        self.weight_momentum = torch.zeros_like(weight)\n",
    "        self.grad_momentum = torch.zeros_like(weight)\n",
    "        self.lr = lr\n",
    "    \n",
    "    def step(self, weight, grad):\n",
    "        self.grad_momentum = self.momentum_coeff * self.grad_momentum + (1 - self.momentum_coeff) * grad**2\n",
    "        delta_w = - torch.sqrt(self.weight_momentum + DELTA_EPSILON) / torch.sqrt(self.grad_momentum + DELTA_EPSILON) * grad\n",
    "        self.weight_momentum = self.momentum_coeff * self.weight_momentum + (1 - self.momentum_coeff) * delta_w**2\n",
    "        weight += delta_w\n",
    "        return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam(Optimiser):\n",
    "    def __init__(self, weight, lr=0.001, beta_1=0.9, beta_2=0.999):\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.weight_momentum = torch.zeros_like(weight)\n",
    "        self.grad_momentum = torch.zeros_like(weight)\n",
    "        self.t = 0\n",
    "        self.lr = lr\n",
    "    \n",
    "    def step(self, weight, grad):\n",
    "        self.t += 1\n",
    "        self.weight_momentum = self.beta_1 * self.weight_momentum + (1 - self.beta_1) * grad\n",
    "        self.grad_momentum = self.beta_2 * self.grad_momentum + (1 - self.beta_2) * grad**2\n",
    "        m = self.weight_momentum / (1 - self.beta_1**self.t)\n",
    "        v = self.grad_momentum / (1 - self.beta_2**self.t)\n",
    "        weight -= self.lr * m / (torch.sqrt(v) + EPSILON)\n",
    "        return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nadam(Optimiser):\n",
    "    def __init__(self, weight, lr=0.002, beta_1=0.9, beta_2=0.999):\n",
    "        super().__init__(weight, lr)\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.weight_momentum = torch.zeros_like(weight)\n",
    "        self.grad_momentum = torch.zeros_like(weight)\n",
    "        self.t = 0\n",
    "\n",
    "    def step(self, weight, grad):\n",
    "        self.t += 1\n",
    "        self.weight_momentum = self.beta_1 * self.weight_momentum + (1 - self.beta_1) * grad\n",
    "        self.grad_momentum = self.beta_2 * self.grad_momentum + (1 - self.beta_2) * grad**2\n",
    "        m = self.weight_momentum / (1 - self.beta_1**self.t)\n",
    "        v = self.grad_momentum / (1 - self.beta_2**self.t)\n",
    "        weight -= self.lr * (self.beta_1 * m + (1 - self.beta_1) * grad / (1 - self.beta_1**self.t)) \\\n",
    "                    / (torch.sqrt(v) + EPSILON)\n",
    "        return weight \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AMSGrad(Optimiser):\n",
    "    def __init__(self, weight, lr=0.001, beta_1=0.9, beta_2=0.999):\n",
    "        super().__init__(weight, lr)\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.weight_momentum = torch.zeros_like(weight)\n",
    "        self.grad_momentum = torch.zeros_like(weight)\n",
    "        self.v = torch.zeros_like(weight)\n",
    "        self.t = 0\n",
    "\n",
    "    def step(self, weight, grad):\n",
    "        self.t += 1\n",
    "        self.weight_momentum = self.beta_1 * self.weight_momentum + (1 - self.beta_1) * grad\n",
    "        self.grad_momentum = self.beta_2 * self.grad_momentum + (1 - self.beta_2) * grad**2\n",
    "        self.v = torch.max(self.v, self.grad_momentum)\n",
    "        m = self.weight_momentum / (1 - self.beta_1**self.t)\n",
    "        weight -= self.lr * m / (torch.sqrt(self.v) + EPSILON)\n",
    "        return weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BarzilaiBorwein(Optimiser):\n",
    "    def __init__(self, weight, lr=0.1):\n",
    "        self.lr = lr\n",
    "        self.prev_weight = None\n",
    "        self.prev_grad = None\n",
    "        self.alpha = lr\n",
    "\n",
    "    def step(self, weight, grad):\n",
    "        if self.prev_weight is None or self.prev_grad is None:\n",
    "            self.alpha = self.lr\n",
    "            self.prev_weight = weight.clone().detach()\n",
    "        else:\n",
    "            s = weight - self.prev_weight.clone().detach()\n",
    "            y = grad - self.prev_grad.clone().detach()\n",
    "            norm = torch.sum(s * y)\n",
    "            if abs(norm.item()) < EPSILON:\n",
    "                self.alpha = self.lr\n",
    "            else:\n",
    "                self.alpha = torch.sum(s * s) / (norm + EPSILON)\n",
    "                if self.alpha <= 0:\n",
    "                    self.alpha = self.lr\n",
    "        self.prev_weight = weight.clone().detach()\n",
    "        self.prev_grad = grad.clone().detach()\n",
    "        weight -= self.alpha * grad\n",
    "        return weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_schulz(M, num_iters=5):\n",
    "    if M.dim() < 2:\n",
    "        return M\n",
    "    norm = torch.norm(M, p='fro')\n",
    "    X = M / (norm + EPSILON)\n",
    "    a = 3.4445\n",
    "    b = -4.7750\n",
    "    c = 2.0315\n",
    "    for _ in range(num_iters):\n",
    "        XtX = X @ X.transpose(-2, -1)\n",
    "        X = a * X + b * (XtX @ X) + c * ((XtX @ XtX) @ X)\n",
    "    return X\n",
    "\n",
    "# https://arxiv.org/pdf/2502.16982v1  24 Feb 2025\n",
    "class Muon(Optimiser):\n",
    "    def __init__(self, weight, lr=0.1, momentum_coeff=0.75, num_iters=5):\n",
    "        super().__init__(weight, lr)\n",
    "        self.momentum_coeff = momentum_coeff\n",
    "        self.num_iters = num_iters\n",
    "        self.weight_momentum = torch.zeros_like(weight)\n",
    "\n",
    "    def step(self, weight, grad):\n",
    "        self.weight_momentum = self.momentum_coeff * self.weight_momentum + grad\n",
    "        O = newton_schulz(self.weight_momentum, num_iters=self.num_iters)\n",
    "        weight -= self.lr * O\n",
    "        return weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**2\n",
    "\n",
    "x = torch.tensor([-5.0], requires_grad=True)\n",
    "zero = torch.tensor([0.0])\n",
    "opt = vanillaSGD(x, lr=0.1)\n",
    "\n",
    "\n",
    "x_vals = []\n",
    "f_vals = []\n",
    "\n",
    "for i in range(20):\n",
    "    y = f(x)\n",
    "    x_vals.append(x.item())\n",
    "    f_vals.append(y.item())\n",
    "    y.backward()\n",
    "    with torch.no_grad():\n",
    "        x = opt(x, x.grad)\n",
    "        x.grad = zero.clone()\n",
    "\n",
    "x_range = np.linspace(-6, 6, 400)\n",
    "y_range = x_range**2\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(x_range, y_range, label='Loss')\n",
    "plt.plot(x_vals, f_vals, 'ro-', label='Vanilla')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**2 +  torch.sin(10 * x)\n",
    "\n",
    "x = torch.tensor([-5.0], requires_grad=True)\n",
    "zero = torch.tensor([0.0])\n",
    "opt = vanillaSGD(x, lr=0.05)\n",
    "\n",
    "x_vals = []\n",
    "f_vals = []\n",
    "\n",
    "for i in range(20):\n",
    "    y = f(x)\n",
    "    x_vals.append(x.item())\n",
    "    f_vals.append(y.item())\n",
    "    y.backward()\n",
    "    with torch.no_grad():\n",
    "        x = opt(x, x.grad)\n",
    "        x.grad = zero.clone()\n",
    "\n",
    "x_range = torch.linspace(-6, 6, 400)\n",
    "y_range = f(x_range)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(x_range, y_range, label='Loss')\n",
    "plt.plot(x_vals, f_vals, 'ro-', label='Optimizer')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**2 +  torch.sin(10 * x)\n",
    "\n",
    "x = torch.tensor([-5.0], requires_grad=True)\n",
    "zero = torch.tensor([0.0])\n",
    "opt = MomentumSGD(x, lr=0.05, momentum_coeff=0.5)\n",
    "\n",
    "x_vals = []\n",
    "f_vals = []\n",
    "\n",
    "for i in range(20):\n",
    "    y = f(x)\n",
    "    x_vals.append(x.item())\n",
    "    f_vals.append(y.item())\n",
    "    y.backward()\n",
    "    with torch.no_grad():\n",
    "        x = opt(x, x.grad)\n",
    "        x.grad = zero.clone()\n",
    "\n",
    "x_range = torch.linspace(-6, 6, 400)\n",
    "y_range = f(x_range)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(x_range, y_range, label='Loss')\n",
    "plt.plot(x_vals, f_vals, 'ro-', label='Optimizer')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STARTING_POINT = torch.tensor([5.0,5.0])\n",
    "ZERO_ZERO = torch.zeros_like(STARTING_POINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optimization(optimizer,function,starting_point=STARTING_POINT,N = 30):\n",
    "    weight = starting_point.clone().requires_grad_()\n",
    "    \n",
    "    weights = []\n",
    "    losses = []\n",
    "\n",
    "    for i in range(N):\n",
    "        znow = function(weight)\n",
    "        znow.backward() \n",
    "\n",
    "        losses.append(znow.detach().item())\n",
    "        weights.append(weight.detach().clone())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            weight = optimizer(weight,weight.grad)\n",
    "            weight.grad = ZERO_ZERO.clone()\n",
    "\n",
    "    weights = torch.stack(weights).detach().numpy()\n",
    "    losses = torch.tensor(losses).detach().numpy()\n",
    "\n",
    "    return weights,losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "  return x[0]**2 + x[1]**2 / 2\n",
    "\n",
    "path, losses = run_optimization(vanillaSGD(ZERO_ZERO,lr=0.05),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZERS = {\n",
    "    \"vanillaSGD\": vanillaSGD(ZERO_ZERO, lr=0.1),\n",
    "    \"momentumSGD\": MomentumSGD(ZERO_ZERO, lr=0.05,momentum_coeff=0.75),\n",
    "    \"nesterovSGD\": NAG(ZERO_ZERO, lr=0.1,),\n",
    "    \"QHM\": QHM(ZERO_ZERO, lr=0.1),\n",
    "    \"RMSprop\": RMSprop(ZERO_ZERO, lr=0.1),\n",
    "    \"Adagrad\": AdaGrad(ZERO_ZERO, lr=0.1),\n",
    "    \"Adadelta\": AdaDelta(ZERO_ZERO, lr=0.1),\n",
    "    \"Adam\": Adam(ZERO_ZERO, lr=0.1),\n",
    "    \"NAdam\": Nadam(ZERO_ZERO,lr=0.1),\n",
    "    \"AMSGrad\": AMSGrad(ZERO_ZERO, lr=0.1),\n",
    "    \"BarzilaiBorwein\": BarzilaiBorwein(ZERO_ZERO, lr=0.1),\n",
    "    \"Muon\": Muon(ZERO_ZERO, lr=0.1)\n",
    "}\n",
    "\n",
    "def run_optimizations(f, starting_point = STARTING_POINT, optims=OPTIMIZERS,N = 30):\n",
    "    results = {}\n",
    "    for name, opt in optims.items():\n",
    "        print(f\"running optimizer: {name}\")\n",
    "        weights, losses = run_optimization(opt,f,starting_point=starting_point,N = N)\n",
    "        results[name] = (weights, losses)\n",
    "    return results\n",
    "\n",
    "results = run_optimizations(f, N=50)\n",
    "# results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(results, func=f, min_point=None, size=5):\n",
    "    x_range = torch.linspace(-1 * size, size, 100)\n",
    "    y_range = np.linspace(-1 * size, size, 100)\n",
    "    X, Y = np.meshgrid(x_range, y_range)\n",
    "    Z = func(torch.tensor([X, Y]))\n",
    "\n",
    "    optimizers = list(results.keys())\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Surface(x=X, y=Y, z=Z.numpy(), colorscale='Viridis', opacity=0.8, showscale=False))\n",
    "    if min_point is not None:\n",
    "        fig.add_trace(go.Scatter3d(x=[min_point[0]], y=[min_point[1]], z=[f(min_point)],\n",
    "                                   mode='markers', marker=dict(color='red', size=5), name='Local Min'))\n",
    "    for name in optimizers:\n",
    "        weights, losses = results[name]\n",
    "        fig.add_trace(go.Scatter3d(x=weights[:, 0], y=weights[:, 1], z=losses,\n",
    "                                   mode='lines', name=name))\n",
    "    fig.update_layout(\n",
    "        title='Optimizers',\n",
    "        scene=dict(xaxis_title='X', yaxis_title='Y', zaxis_title='Loss',\n",
    "                   aspectmode='manual', aspectratio=dict(x=1, y=1, z=0.5))\n",
    "    )\n",
    "    fig.update_layout(width=1000, height=1000)\n",
    "    fig.show()\n",
    "\n",
    "plot(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate(results, min_point=None):\n",
    "    import plotly.graph_objects as go\n",
    "    import numpy as np\n",
    "    x_range = np.linspace(-5, 5, 100)\n",
    "    y_range = np.linspace(-5, 5, 100)\n",
    "    X, Y = np.meshgrid(x_range, y_range)\n",
    "    Z = f([X, Y])\n",
    "    num_frames = list(results.values())[0][0].shape[0]\n",
    "    optimizers = list(results.keys())\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Surface(x=X, y=Y, z=Z, colorscale='Viridis', opacity=0.8, showscale=False))\n",
    "    offset = 1\n",
    "    if min_point is not None:\n",
    "        fig.add_trace(go.Scatter3d(x=[min_point[0]], y=[min_point[1]], z=[f(min_point)],\n",
    "                                   mode='markers', marker=dict(color='red', size=5), name='Local Min'))\n",
    "        offset = 2\n",
    "    for name in optimizers:\n",
    "        weights, losses = results[name]\n",
    "        fig.add_trace(go.Scatter3d(x=[weights[0, 0]], y=[weights[0, 1]], z=[losses[0]],\n",
    "                                   mode='lines', name=name))\n",
    "    frames = []\n",
    "    for i in range(num_frames):\n",
    "        data = []\n",
    "        for name in optimizers:\n",
    "            weights, losses = results[name]\n",
    "            data.append(go.Scatter3d(x=weights[:i+1, 0], y=weights[:i+1, 1], z=losses[:i+1],\n",
    "                                     mode='lines', name=name))\n",
    "        frames.append(go.Frame(data=data, name=str(i), traces=list(range(offset, offset+len(optimizers)))))\n",
    "    fig.frames = frames\n",
    "    fig.update_layout(\n",
    "        title='Optimizers',\n",
    "        scene=dict(xaxis_title='X', yaxis_title='Y', zaxis_title='Loss',\n",
    "                   aspectmode='manual', aspectratio=dict(x=1, y=1, z=0.5)),\n",
    "        updatemenus=[dict(\n",
    "            type='buttons',\n",
    "            showactive=False,\n",
    "            y=1,\n",
    "            x=1.3,\n",
    "            xanchor='right',\n",
    "            yanchor='top',\n",
    "            buttons=[\n",
    "                dict(label='Play', method='animate', args=[None, {\"frame\": {\"duration\": 50, \"redraw\": True},\n",
    "                                                                   \"fromcurrent\": True, \"transition\": {\"duration\": 0}}]),\n",
    "                dict(label='Pause', method='animate', args=[[None], {\"frame\": {\"duration\": 0, \"redraw\": False},\n",
    "                                                                      \"mode\": \"immediate\", \"transition\": {\"duration\": 0}}])\n",
    "            ]\n",
    "        )],\n",
    "        sliders=[dict(\n",
    "            steps=[dict(method='animate', args=[[str(i)], dict(mode='immediate', frame={'duration': 50, 'redraw': True},\n",
    "                                                              transition={'duration': 0})], label=str(i))\n",
    "                   for i in range(num_frames)],\n",
    "            active=0,\n",
    "            transition={'duration': 0},\n",
    "            x=0.1,\n",
    "            y=0,\n",
    "            currentvalue=dict(font=dict(size=12), prefix='Iteration: ', visible=True, xanchor='center'),\n",
    "            len=0.9\n",
    "        )]\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "animate(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.01,  0.1, 0.5, 1.0]\n",
    "optimizers = {f\"vanillaSGD_lr_{lr}\": vanillaSGD(ZERO_ZERO, lr=lr) for lr in learning_rates}\n",
    "\n",
    "results_momentum_lrs = run_optimizations(f, N=50, optims=optimizers)\n",
    "plot(results_momentum_lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.03, 0.1]\n",
    "optimizers = {f\"momentumSGD_lr_{lr}\": MomentumSGD(ZERO_ZERO, lr=lr,momentum_coeff=0.8) for lr in learning_rates}\n",
    "\n",
    "results_momentum_lrs = run_optimizations(f, N=50, optims=optimizers)\n",
    "plot(results_momentum_lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "momentum_coeffs = [0.1,0.3,0.6,0.7,0.8,0.95]\n",
    "optimisers = {f\"momentumSGD_{momentum_coeff}\": MomentumSGD(ZERO_ZERO, lr=learning_rate,momentum_coeff=momentum_coeff) for momentum_coeff in momentum_coeffs}\n",
    "\n",
    "results_momentum_lrs = run_optimizations(f, N=50, optims=optimisers)\n",
    "plot(results_momentum_lrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# other surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def himmelblau(x):\n",
    "    return (x[0]**2 + x[1] - 11)**2 + (x[0] + x[1]**2 - 7)**2\n",
    "\n",
    "learning_rate = 0.1\n",
    "optimizers = {\n",
    "    \"vanillaSGD\": vanillaSGD(ZERO_ZERO, lr=0.01),\n",
    "    \"momentumSGD\": MomentumSGD(ZERO_ZERO, lr=0.01,momentum_coeff=0.2),\n",
    "    \"nesterovSGD\": NAG(ZERO_ZERO, lr=0.01,momentum_coeff=0.2),\n",
    "    \"QHM\": QHM(ZERO_ZERO, lr=0.01,momentum_coeff=0.2),\n",
    "    \"Muon\": Muon(ZERO_ZERO, lr=0.01, momentum_coeff=0.2),\n",
    "    \"RMSprop\": RMSprop(ZERO_ZERO, lr=learning_rate),\n",
    "    \"Adagrad\": AdaGrad(ZERO_ZERO, lr=0.5),\n",
    "    \"Adadelta\": AdaDelta(ZERO_ZERO, lr=1.0),\n",
    "    \"Adam\": Adam(ZERO_ZERO, lr=learning_rate),\n",
    "    \"AMSGrad\": AMSGrad(ZERO_ZERO, lr=0.1),\n",
    "    \"BarzilaiBorwein\": BarzilaiBorwein(ZERO_ZERO, lr=0.01),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results_himmelblau = run_optimizations(himmelblau, N=50,starting_point=torch.tensor([5.0,5.0]), optims=optimizers)\n",
    "plot(results_himmelblau, size=5, func=himmelblau)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learning_rate = 0.1\n",
    "optimizers = {\n",
    "    \"vanillaSGD\": vanillaSGD(ZERO_ZERO, lr=0.005),\n",
    "    \"momentumSGD\": MomentumSGD(ZERO_ZERO, lr=0.005,momentum_coeff=0.5),\n",
    "    \"nesterovSGD\": NAG(ZERO_ZERO, lr=0.005,momentum_coeff=0.5),\n",
    "    \"QHM\": QHM(ZERO_ZERO, lr=0.005,momentum_coeff=0.5),\n",
    "    \"Muon\": Muon(ZERO_ZERO, lr=0.005, momentum_coeff=0.5),\n",
    "    \"RMSprop\": RMSprop(ZERO_ZERO, lr=learning_rate),\n",
    "    \"Adagrad\": AdaGrad(ZERO_ZERO, lr=0.5),\n",
    "    \"Adadelta\": AdaDelta(ZERO_ZERO, lr=1.0),\n",
    "    \"Adam\": Adam(ZERO_ZERO, lr=learning_rate),\n",
    "    \"AMSGrad\": AMSGrad(ZERO_ZERO, lr=0.1),\n",
    "    \"BarzilaiBorwein\": BarzilaiBorwein(ZERO_ZERO, lr=0.01),\n",
    "}\n",
    "\n",
    "results_himmelblau = run_optimizations(himmelblau, N=50,starting_point=torch.tensor([0.0,-6.0]), optims=optimizers)\n",
    "plot(results_himmelblau, size=6.5, func=himmelblau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def local_min(x):\n",
    "    return x[0]**2 - x[1] **2 + (x[1] **4)/50\n",
    "\n",
    "\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "optimizers = {\n",
    "    \"vanillaSGD\": vanillaSGD(ZERO_ZERO, lr=0.01),\n",
    "    \"momentumSGD\": MomentumSGD(ZERO_ZERO, lr=0.01,momentum_coeff=0.2),\n",
    "    \"nesterovSGD\": NAG(ZERO_ZERO, lr=0.01,momentum_coeff=0.2),\n",
    "    \"QHM\": QHM(ZERO_ZERO, lr=0.01,momentum_coeff=0.2),\n",
    "    \"Muon\": Muon(ZERO_ZERO, lr=0.01, momentum_coeff=0.2),\n",
    "    \"RMSprop\": RMSprop(ZERO_ZERO, lr=learning_rate),\n",
    "    \"Adagrad\": AdaGrad(ZERO_ZERO, lr=0.5),\n",
    "    \"Adadelta\": AdaDelta(ZERO_ZERO, lr=1.0),\n",
    "    \"Adam\": Adam(ZERO_ZERO, lr=learning_rate),\n",
    "    \"AMSGrad\": AMSGrad(ZERO_ZERO, lr=0.1),\n",
    "    \"BarzilaiBorwein\": BarzilaiBorwein(ZERO_ZERO, lr=0.005),\n",
    "}\n",
    "\n",
    "\n",
    "results_sphere = run_optimizations(local_min, N=150,starting_point=torch.tensor([6.0, 0.05]), optims=optimizers)\n",
    "plot(results_sphere, size=6, func=local_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def local_min(x):\n",
    "    return x[0]**2 - x[1] **2 + (x[1] **4)/50\n",
    "\n",
    "\n",
    "\n",
    "learning_rate = 0.1\n",
    "optimizers = {\n",
    "    \"vanillaSGD\": vanillaSGD(ZERO_ZERO, lr=0.01),\n",
    "    \"momentumSGD\": MomentumSGD(ZERO_ZERO, lr=0.01,momentum_coeff=0.2),\n",
    "    \"nesterovSGD\": NAG(ZERO_ZERO, lr=0.01,momentum_coeff=0.2),\n",
    "    \"QHM\": QHM(ZERO_ZERO, lr=0.01,momentum_coeff=0.2),\n",
    "    \"Muon\": Muon(ZERO_ZERO, lr=0.01, momentum_coeff=0.2),\n",
    "    \"RMSprop\": RMSprop(ZERO_ZERO, lr=learning_rate),\n",
    "    \"Adagrad\": AdaGrad(ZERO_ZERO, lr=0.5),\n",
    "    \"Adadelta\": AdaDelta(ZERO_ZERO, lr=1.0),\n",
    "    \"Adam\": Adam(ZERO_ZERO, lr=learning_rate),\n",
    "    \"AMSGrad\": AMSGrad(ZERO_ZERO, lr=0.1),\n",
    "    \"BarzilaiBorwein\": BarzilaiBorwein(ZERO_ZERO, lr=0.005),\n",
    "}\n",
    "\n",
    "results_sphere = run_optimizations(local_min, N=150,starting_point=torch.tensor([1.5, 0.01]), optims=optimizers)\n",
    "plot(results_sphere, size=6, func=local_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_min(x):\n",
    "    return  ((x[0]-2)**2 +(x[1]-2) **2) - 5 * (1 / (0.1 + x[0]**4 + x[1]**4) )\n",
    "\n",
    "optimizers = {\n",
    "    \"vanillaSGD\": vanillaSGD(ZERO_ZERO, lr=0.01),\n",
    "    \"momentumSGD\": MomentumSGD(ZERO_ZERO, lr=0.01,momentum_coeff=0.2),\n",
    "    \"nesterovSGD\": NAG(ZERO_ZERO, lr=0.01,momentum_coeff=0.2),\n",
    "    \"QHM\": QHM(ZERO_ZERO, lr=0.01,momentum_coeff=0.2),\n",
    "    \"Muon\": Muon(ZERO_ZERO, lr=0.01, momentum_coeff=0.2),\n",
    "    \"RMSprop\": RMSprop(ZERO_ZERO, lr=learning_rate),\n",
    "    \"Adagrad\": AdaGrad(ZERO_ZERO, lr=0.5),\n",
    "    \"Adadelta\": AdaDelta(ZERO_ZERO, lr=1.0),\n",
    "    \"Adam\": Adam(ZERO_ZERO, lr=learning_rate),\n",
    "    \"AMSGrad\": AMSGrad(ZERO_ZERO, lr=0.1),\n",
    "    \"BarzilaiBorwein\": BarzilaiBorwein(ZERO_ZERO, lr=0.01),\n",
    "}\n",
    "\n",
    "results_sphere = run_optimizations(local_min, N=150,starting_point=torch.tensor([-3.0, 3.0]), optims=optimizers)\n",
    "plot(results_sphere, size=3, func=local_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
